{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160742, 7)\n",
      "(306313, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>100:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>163606</td>\n",
       "      <td>1569</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>200:30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160421.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3273056</td>\n",
       "      <td>4833</td>\n",
       "      <td>7802.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160130.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94107</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160412.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>253750</td>\n",
       "      <td>8390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>253750</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160327.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>376492</td>\n",
       "      <td>1041</td>\n",
       "      <td>13490.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160127.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1964720</td>\n",
       "      <td>7884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1964720</td>\n",
       "      <td>7884</td>\n",
       "      <td>6704.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160215.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1113008</td>\n",
       "      <td>1041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1113008</td>\n",
       "      <td>1041</td>\n",
       "      <td>11197.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160114.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2881376</td>\n",
       "      <td>5341</td>\n",
       "      <td>111.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2881376</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160321.0</td>\n",
       "      <td>20160329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2881376</td>\n",
       "      <td>5341</td>\n",
       "      <td>111.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0   1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1   1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2   1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3   1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4   2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "5   2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "6     73611         2099    12034.0        100:10       NaN     20160207.0   \n",
       "7    163606         1569     5054.0        200:30      10.0     20160421.0   \n",
       "8   3273056         4833     7802.0        200:20      10.0     20160130.0   \n",
       "9     94107         3381     7610.0        200:20       2.0     20160412.0   \n",
       "10   253750         8390        NaN           NaN       0.0            NaN   \n",
       "11   253750         8390     7531.0          20:5       0.0     20160327.0   \n",
       "12   376492         1041    13490.0          30:5       2.0     20160127.0   \n",
       "13  1964720         7884        NaN           NaN      10.0            NaN   \n",
       "14  1964720         7884     6704.0          20:1      10.0     20160215.0   \n",
       "15  1113008         1041        NaN           NaN       2.0            NaN   \n",
       "16  1113008         1041    11197.0          30:5       2.0     20160114.0   \n",
       "17  2881376         5341      111.0          30:5       1.0     20160207.0   \n",
       "18  2881376         8390     7531.0          20:5       0.0     20160321.0   \n",
       "19  2881376         5341      111.0          30:5       1.0     20160207.0   \n",
       "\n",
       "          Date  \n",
       "0   20160217.0  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10  20160327.0  \n",
       "11         NaN  \n",
       "12         NaN  \n",
       "13  20160115.0  \n",
       "14         NaN  \n",
       "15  20160114.0  \n",
       "16         NaN  \n",
       "17         NaN  \n",
       "18  20160329.0  \n",
       "19         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfoff = pd.read_csv('train_offline.csv')\n",
    "dftest = pd.read_csv('test_offline.csv')\n",
    "dftest = dftest[~dftest.Coupon_id.isna()]\n",
    "dftest.reset_index(drop=True, inplace=True)\n",
    "print(dfoff.shape)\n",
    "print(dftest.shape)\n",
    "dfoff.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    710665\n",
       "-1    413773\n",
       " 1     36304\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creat target label \n",
    "\"\"\"\n",
    "According to the definition, \n",
    "1) buy with coupon within (include) 15 days ==> 1\n",
    "2) buy with coupon but out of 15 days ==> 0\n",
    "3) buy without coupon ==> -1 (we don't care)\n",
    "\"\"\"\n",
    "def label(row):\n",
    "    if np.isnan(row['Date_received']):\n",
    "        return -1\n",
    "    if not np.isnan(row['Date']):\n",
    "        td = pd.to_datetime(row['Date'], format='%Y%m%d') -  pd.to_datetime(row['Date_received'], format='%Y%m%d')\n",
    "        if td <= pd.Timedelta(15, 'D'):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "dfoff[\"label\"] = dfoff.apply(label, axis=1)\n",
    "dfoff[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features - weekday acquired coupon\n",
    "def getWeekday(row):\n",
    "    if (np.isnan(row)) or (row==-1):\n",
    "        return row\n",
    "    else:\n",
    "        return pd.to_datetime(row, format = \"%Y%m%d\").dayofweek+1 # add one to make it from 0~6 -> 1~7\n",
    "\n",
    "dfoff['weekday'] = dfoff['Date_received'].apply(getWeekday)\n",
    "dftest['weekday'] = dftest['Date_received'].apply(getWeekday)\n",
    "\n",
    "# weekday_type (weekend = 1)\n",
    "dfoff['weekday_type'] = dfoff['weekday'].astype('str').apply(lambda x : 1 if x in [6,7] else 0 ) # apply to trainset\n",
    "dftest['weekday_type'] = dftest['weekday'].astype('str').apply(lambda x : 1 if x in [6,7] else 0 ) # apply to testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "weekdaycols = ['weekday_' + str(i) for i in range(1,8)]\n",
    "print(weekdaycols)\n",
    "\n",
    "tmpdf = pd.get_dummies(dfoff['weekday'].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dfoff[weekdaycols] = tmpdf\n",
    "\n",
    "tmpdf = pd.get_dummies(dftest['weekday'].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dftest[weekdaycols] = tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features - coupon discount and distance\n",
    "def getDiscountType(row):\n",
    "    if row == 'null':\n",
    "        return 'null'\n",
    "    elif ':' in row:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def convertRate(row):\n",
    "    \"\"\"Convert discount to rate\"\"\"\n",
    "    if row == 'null':\n",
    "        return 1.0\n",
    "    elif ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return 1.0 - float(rows[1])/float(rows[0])\n",
    "    else:\n",
    "        return float(row)\n",
    "\n",
    "def getDiscountMan(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def getDiscountJian(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[1])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def processData(df):\n",
    "    \n",
    "    # convert discunt_rate\n",
    "    df['discount_rate'] = df['Discount_rate'].astype('str').apply(convertRate)\n",
    "    df['discount_man'] = df['Discount_rate'].astype('str').apply(getDiscountMan)\n",
    "    df['discount_jian'] = df['Discount_rate'].astype('str').apply(getDiscountJian)\n",
    "    df['discount_type'] = df['Discount_rate'].astype('str').apply(getDiscountType)\n",
    "    \n",
    "    # convert distance\n",
    "    df.loc[df.Distance.isna(), \"Distance\"] = 99\n",
    "    return df\n",
    "\n",
    "dfoff = processData(dfoff)\n",
    "dftest = processData(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 667753, #positive: 32472\n",
      "Valid size: 79216, #positive: 3832\n"
     ]
    }
   ],
   "source": [
    "## Naive model\n",
    "def split_train_valid(row, date_cut=\"20160416\"):\n",
    "    is_train = True if pd.to_datetime(row, format=\"%Y%m%d\") < pd.to_datetime(date_cut, format=\"%Y%m%d\") else False\n",
    "    return is_train\n",
    "    \n",
    "df = dfoff[dfoff['label'] != -1].copy()\n",
    "df[\"is_train\"] = df[\"Date_received\"].apply(split_train_valid)\n",
    "train = df[df[\"is_train\"]]\n",
    "valid = df[~df[\"is_train\"]]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "print(\"Train size: {}, #positive: {}\".format(len(train), train[\"label\"].sum()))\n",
    "print(\"Valid size: {}, #positive: {}\".format(len(valid), valid[\"label\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 ['discount_rate', 'discount_type', 'discount_man', 'discount_jian', 'Distance', 'weekday', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "original_feature = ['discount_rate',\n",
    "                    'discount_type',\n",
    "                    'discount_man', \n",
    "                    'discount_jian',\n",
    "                    'Distance', \n",
    "                    'weekday', \n",
    "                    'weekday_type'] + weekdaycols\n",
    "print(len(original_feature),original_feature)\n",
    "predictors = original_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>label</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>weekday_7</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>discount_man</th>\n",
       "      <th>discount_jian</th>\n",
       "      <th>discount_type</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>100:10</td>\n",
       "      <td>99.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "1  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "2  2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "3  2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "4    73611         2099    12034.0        100:10      99.0     20160207.0   \n",
       "\n",
       "   Date  label  weekday  weekday_type  ...  weekday_3  weekday_4  weekday_5  \\\n",
       "0   NaN      0      3.0             0  ...          1          0          0   \n",
       "1   NaN      0      6.0             0  ...          0          0          0   \n",
       "2   NaN      0      5.0             0  ...          0          0          1   \n",
       "3   NaN      0      5.0             0  ...          0          0          1   \n",
       "4   NaN      0      7.0             0  ...          0          0          0   \n",
       "\n",
       "   weekday_6  weekday_7  discount_rate  discount_man  discount_jian  \\\n",
       "0          0          0           0.95            20              1   \n",
       "1          1          0           0.95            20              1   \n",
       "2          0          0           0.90           200             20   \n",
       "3          0          0           0.50            10              5   \n",
       "4          0          1           0.90           100             10   \n",
       "\n",
       "   discount_type  is_train  \n",
       "0              1      True  \n",
       "1              1      True  \n",
       "2              1      True  \n",
       "3              1      True  \n",
       "4              1      True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_id            int64\n",
       "Merchant_id        int64\n",
       "Coupon_id        float64\n",
       "Discount_rate     object\n",
       "Distance         float64\n",
       "Date_received    float64\n",
       "Date             float64\n",
       "label              int64\n",
       "weekday          float64\n",
       "weekday_type       int64\n",
       "weekday_1          uint8\n",
       "weekday_2          uint8\n",
       "weekday_3          uint8\n",
       "weekday_4          uint8\n",
       "weekday_5          uint8\n",
       "weekday_6          uint8\n",
       "weekday_7          uint8\n",
       "discount_rate    float64\n",
       "discount_man       int64\n",
       "discount_jian      int64\n",
       "discount_type      int64\n",
       "is_train            bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set a seed for reproducibility'''\n",
    "seed = 43\n",
    "dropcolumns=['User_id','Merchant_id','Coupon_id','Discount_rate','Date_received','Date','is_train']\n",
    "df_train = train.drop(columns = dropcolumns, axis = 1)\n",
    "df_test = valid.drop(columns = dropcolumns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix Dimension:   (667753, 14)\n",
      "Output Vector Dimension:  (667753,)\n",
      "Test Data Dimension:      (79216, 14)\n"
     ]
    }
   ],
   "source": [
    "'''Extract data sets as input and output for machine learning models.'''\n",
    "X_train = df_train.drop(columns = ['label'], axis = 1) \n",
    "y_train = df_train['label']\n",
    "\n",
    "\"\"\"Extract test set\"\"\"\n",
    "X_test  = df_test.drop(columns = ['label'], axis = 1).copy()\n",
    "\n",
    "'''See the dimensions of input and output data set.'''\n",
    "print('Input Matrix Dimension:  ', X_train.shape)\n",
    "print('Output Vector Dimension: ', y_train.shape)\n",
    "print('Test Data Dimension:     ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#1.Logistic Regression'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "'''#3.Random Forest Classifier'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state = seed, n_estimators = 100)\n",
    "\n",
    "'''#4.KNN'''\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "'''#6.Decision Tree Classifier'''\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "'''#7.Gradient Boosting Classifier'''\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state = seed)\n",
    "\n",
    "'''#10.Extreme Gradient Boosting'''\n",
    "from xgboost import XGBClassifier\n",
    "xgbc = XGBClassifier(random_state = seed, tree_method = 'gpu_hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a function that returns train accuracy of different models.'''\n",
    "def train_accuracy(model):\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    train_accuracy = np.round(train_accuracy*100, 2)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    return train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kurel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.781664609909058\n",
      "70.06777453422546\n",
      "567.1314775943756\n",
      "2.0626137256622314\n",
      "59.442872285842896\n",
      "44.190572023391724\n"
     ]
    }
   ],
   "source": [
    "'''Models with best training accuracy:'''\n",
    "train_accuracy = pd.DataFrame({'Train_accuracy(%)':[train_accuracy(lr), train_accuracy(rf), train_accuracy(knn), train_accuracy(dt), train_accuracy(gbc), train_accuracy(xgbc)]})\n",
    "train_accuracy.index = ['LR', 'RF', 'KNN', 'DT', 'GBC', 'XGBC']\n",
    "sorted_train_accuracy = train_accuracy.sort_values(by = 'Train_accuracy(%)', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_accuracy(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>95.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>95.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>95.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBC</th>\n",
       "      <td>95.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBC</th>\n",
       "      <td>95.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train_accuracy(%)\n",
       "LR                95.14\n",
       "RF                95.14\n",
       "DT                95.14\n",
       "GBC               95.14\n",
       "XGBC              95.14\n",
       "KNN               95.00"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kurel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kurel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kurel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kurel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kurel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_val_score(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>95.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBC</th>\n",
       "      <td>95.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBC</th>\n",
       "      <td>95.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>95.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>95.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>94.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X_val_score(%)\n",
       "LR             95.14\n",
       "GBC            95.14\n",
       "XGBC           95.14\n",
       "DT             95.13\n",
       "RF             95.12\n",
       "KNN            94.63"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Create a function that returns mean cross validation score for different models.'''\n",
    "def x_val_score(model):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    x_val_score = cross_val_score(model, X_train, y_train, cv = 5, scoring = 'accuracy').mean()\n",
    "    x_val_score = np.round(x_val_score*100, 2)\n",
    "    return x_val_score\n",
    "\n",
    "\"\"\"Let's perform k-fold (k=5) cross validation to find the classifier with the best cross validation accuracy.\"\"\"\n",
    "x_val_score = pd.DataFrame({'X_val_score(%)':[x_val_score(lr), x_val_score(rf), x_val_score(knn), x_val_score(dt), x_val_score(gbc), x_val_score(xgbc)]})\n",
    "x_val_score.index = ['LR', 'RF', 'KNN', 'DT', 'GBC', 'XGBC']\n",
    "sorted_x_val_score = x_val_score.sort_values(by = 'X_val_score(%)', ascending = False) \n",
    "sorted_x_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Define all the models' hyperparameters one by one first::\"\"\"\n",
    "\n",
    "'''Define hyperparameters the logistic regression will be tuned with. For LR, the following hyperparameters are usually tunned.'''\n",
    "lr_params = {'penalty':['l1', 'l2'],\n",
    "             'C': np.logspace(0, 4, 10)}\n",
    "\n",
    "'''For GBC, the following hyperparameters are usually tunned.'''\n",
    "gbc_params = {'learning_rate': [0.01, 0.02, 0.05],\n",
    "              'max_depth': [4, 6],\n",
    "              'max_features': [1.0, 0.3], \n",
    "              'min_samples_split': [ 2, 3],\n",
    "              'random_state':[seed]}\n",
    "\n",
    "\n",
    "'''For DT, the following hyperparameters are usually tunned.'''\n",
    "dt_params = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'min_samples_split': [2, 3, 4, 8, 9, 10], \n",
    "             'min_samples_leaf':[1, 2, 5, 6, 9, 10],\n",
    "             'random_state':[seed]}\n",
    "\n",
    "'''For RF, the following hyperparameters are usually tunned.'''\n",
    "rf_params = {'criterion':['gini','entropy'],\n",
    "             'n_estimators':[10, 15, 20, 25, 30],\n",
    "             'min_samples_leaf':[1, 2, 3],\n",
    "             'min_samples_split':[3, 4, 5, 6, 7], \n",
    "             'max_features':['sqrt', 'auto', 'log2'],\n",
    "             'random_state':[44]}\n",
    "\n",
    "'''For KNN, the following hyperparameters are usually tunned.'''\n",
    "knn_params = {'n_neighbors':[3, 5, 7],\n",
    "              'leaf_size':[1, 3, 5],\n",
    "              'weights':['uniform', 'distance'],\n",
    "              'algorithm':['auto', 'ball_tree','kd_tree','brute']}\n",
    "\n",
    "\n",
    "'''For XGBC, the following hyperparameters are usually tunned.'''\n",
    "xgbc_params = {'n_estimators': (150, 550, 850),\n",
    "              'learning_rate': (0.01, 0.6),\n",
    "              'subsample': (0.3, 0.9),\n",
    "              'max_depth': [3, 5, 7],\n",
    "              'colsample_bytree': (0.5, 0.9),\n",
    "              'min_child_weight': [1, 3],\n",
    "              'random_state':[seed]}\n",
    "\n",
    "\n",
    "'''Create a function to tune hyperparameters of the selected models.'''\n",
    "def tune_hyperparameters(model, params):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    global best_params, best_score\n",
    "    # Construct grid search object with 10 fold cross validation.\n",
    "    grid = GridSearchCV(model, params, verbose = 10, cv = 3, scoring = 'accuracy', n_jobs = -1)\n",
    "    # Fit using grid search.\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_params, best_score = grid.best_params_, np.round(grid.best_score_*100, 2)\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  60 | elapsed:  5.4min remaining:   49.6s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  5.9min finished\n",
      "C:\\Users\\Kurel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Best Score: 95.14\n",
      "And Best Parameters: {'C': 1.0, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# '''Tune LR hyperparameters.'''\n",
    "# tune_hyperparameters(lr, params = lr_params)\n",
    "# lr_best_params, lr_best_score = best_params, best_score\n",
    "# print('LR Best Score:', lr_best_score)\n",
    "# print('And Best Parameters:', lr_best_params)\n",
    "\n",
    "# \"\"\"Tune GBC's hyperparameters.\"\"\"\n",
    "# tune_hyperparameters(gbc, params = gbc_params)\n",
    "# gbc_best_score, gbc_best_params = best_score, best_params\n",
    "# print('GBC Best Score:', gbc_best_score)\n",
    "# print('And Best Parameters:', gbc_best_params)\n",
    "\n",
    "# \"\"\"Tune DT's hyperparameters.\"\"\"\n",
    "# tune_hyperparameters(dt, params = dt_params)\n",
    "# dt_best_score, dt_best_params = best_score, best_params\n",
    "# print('DT Best Score:', dt_best_score)\n",
    "# print('And Best Parameters:', dt_best_params)\n",
    "\n",
    "# \"\"\"Tune RF's hyperparameters.\"\"\"\n",
    "# tune_hyperparameters(rf, params = rf_params)\n",
    "# rf_best_score, rf_best_params = best_score, best_params\n",
    "# print('RF Best Score:', rf_best_score)\n",
    "# print('And Best Parameters:', rf_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_params = {'C': 1.0, 'penalty': 'l1'}\n",
    "gbc_best_params = {'learning_rate': 0.01, 'max_depth': 4, 'max_features': 1.0, 'min_samples_split': 2, 'random_state': 43}\n",
    "dt_best_params = {'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 2, 'random_state': 43}\n",
    "rf_best_params = {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 25, 'random_state': 44}\n",
    "xgbc_best_params = {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 550, 'random_state': 43, 'subsample': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 57.8min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 70.8min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 87.8min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 103.7min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 113.2min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 124.4min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 141.5min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 156.8min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 183.6min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 205.0min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed: 224.4min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 248.0min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed: 287.2min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed: 330.6min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 355.3min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed: 382.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed: 424.7min\n",
      "[Parallel(n_jobs=-1)]: Done 432 out of 432 | elapsed: 471.9min finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Tune XGBC's hyperparameters.\"\"\"\n",
    "tune_hyperparameters(xgbc, params = xgbc_params)\n",
    "xgbc_best_score, xgbc_best_params = best_score, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 95.1320 (+/- 0.0024) [RF]\n",
      "Mean Accuracy: 95.1371 (+/- 0.0000) [GBC]\n",
      "Mean Accuracy: 93.7156 (+/- 0.7781) [KNN]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kurel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kurel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kurel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kurel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 95.1371 (+/- 0.0000) [LR]\n",
      "Mean Accuracy: 95.1376 (+/- 0.0004) [DT]\n",
      "Mean Accuracy: 95.1371 (+/- 0.0000) [XGBC]\n"
     ]
    }
   ],
   "source": [
    "'''Instantiate the models with optimized hyperparameters.'''\n",
    "rf  = RandomForestClassifier(**rf_best_params)\n",
    "gbc = GradientBoostingClassifier(**gbc_best_params)\n",
    "knn = KNeighborsClassifier()\n",
    "lr  = LogisticRegression(**lr_best_params)\n",
    "dt  = DecisionTreeClassifier(**dt_best_params)\n",
    "xgbc = XGBClassifier(**dt_best_params)\n",
    "\n",
    "'''Train all the models with optimised hyperparameters.'''\n",
    "models = {'RF':rf, 'GBC':gbc, 'KNN':knn, 'LR':lr, 'DT':dt, 'XGBC':xgbc}\n",
    "score = []\n",
    "for x, (keys, items) in enumerate(models.items()):\n",
    "    # Train the models with optimized parameters using cross validation.\n",
    "    # No need to fit the data. cross_val_score does that for us.\n",
    "    # But we need to fit train data for prediction in the follow session.\n",
    "    items.fit(X_train, y_train)\n",
    "    scores = cross_val_score(items, X_train, y_train, cv = 3, scoring = 'accuracy')*100\n",
    "    score.append(scores.mean())\n",
    "    print('Mean Accuracy: %0.4f (+/- %0.4f) [%s]'  % (scores.mean(), scores.std(), keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>GBC</th>\n",
       "      <th>DT</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>XGBC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017032</td>\n",
       "      <td>0.028816</td>\n",
       "      <td>0.016731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>0.017751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0.002886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010207</td>\n",
       "      <td>0.022148</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.003572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055365</td>\n",
       "      <td>0.054368</td>\n",
       "      <td>0.054784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059208</td>\n",
       "      <td>0.063646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.022148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>0.003607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RF       GBC        DT  KNN        LR      XGBC\n",
       "0  0.017032  0.028816  0.016731  0.0  0.005943  0.017751\n",
       "1  0.000000  0.022148  0.000000  0.0  0.005474  0.002886\n",
       "2  0.010207  0.022148  0.010568  0.0  0.007932  0.003572\n",
       "3  0.055365  0.054368  0.054784  0.0  0.059208  0.063646\n",
       "4  0.000077  0.022148  0.000000  0.0  0.005658  0.003607"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Make prediction using all the trained models.'''\n",
    "model_prediction = pd.DataFrame({'RF':rf.predict_proba(X_test)[:,1], 'GBC':gbc.predict_proba(X_test)[:,1], \n",
    "                                 'DT':dt.predict_proba(X_test)[:,1], 'KNN':knn.predict_proba(X_test)[:,1], \n",
    "                                 'LR':lr.predict_proba(X_test)[:,1],'XGBC':xgbc.predict_proba(X_test)[:,1]})\n",
    "\n",
    "\"\"\"Let's see how each model classifies a prticular class.\"\"\"\n",
    "model_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {'RF':rf,'GBC':gbc,'DT':dt,'KNN':knn,'LR':lr,'XGBC':xgbc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (key, value) in enumerate(model_dict.items()):\n",
    "    auc_score = roc_auc_score(y_true=df_test.label, y_score=value.predict_proba(X_test)[:,1])\n",
    "    acc = accuracy_score(y_true=df_test.label, y_pred=value.predict_proba(X_test).argmax(axis=1))\n",
    "    print(\"{}: Validation AUC: {:.3f}, Accuracy: {:.3f}\".format(key, auc_score, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC: Validation AUC: 0.785, Accuracy: 0.952 (before optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 19)\n"
     ]
    }
   ],
   "source": [
    "targetset = dftest.copy()\n",
    "print(targetset.shape)\n",
    "targetset = targetset[~targetset.Coupon_id.isna()]\n",
    "targetset.reset_index(drop=True, inplace=True)\n",
    "testset = targetset[predictors].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, (key, value) in enumerate(model_dict.items()):\n",
    "    y_test_pred = value.predict_proba(testset[X_test.columns])\n",
    "    test1 = testset.copy()\n",
    "    test1['pred_prob'] = y_test_pred[:, 1]\n",
    "    #print(test1.shape)\n",
    "\n",
    "    output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], test1[\"pred_prob\"]), axis=1)\n",
    "    #print(output.shape)\n",
    "\n",
    "    output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\n",
    "    output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\n",
    "    output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\n",
    "    output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "    output.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    ### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\n",
    "    out = output.groupby(\"uid\", as_index=False).mean()\n",
    "    out = out[[\"uid\", \"pred_prob\"]]\n",
    "    out.columns = [\"uid\", \"label\"]\n",
    "    out.to_csv(\"{}.csv\".format(key), header=[\"uid\", \"label\"], index=False) # submission format\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Bagging Ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:   53.1s remaining:  2.7min\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:   55.1s remaining:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   8 | elapsed:   55.7s remaining:   55.7s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:   55.8s remaining:   33.4s\n",
      "[Parallel(n_jobs=8)]: Done   6 out of   8 | elapsed:   56.2s remaining:   18.7s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    2.9s remaining:    8.9s\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    3.0s remaining:    5.1s\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   8 | elapsed:    3.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    3.1s remaining:    1.8s\n",
      "[Parallel(n_jobs=8)]: Done   6 out of   8 | elapsed:    3.1s remaining:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    4.2s finished\n"
     ]
    }
   ],
   "source": [
    "'''Initialize bagging classifier.'''\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagg = BaggingClassifier(base_estimator = rf, verbose = 10, n_jobs = -1, random_state = seed)\n",
    "'''We use rf as the base estimator for bagging technique.'''\n",
    "print('Fitting Bagging Ensemble...')\n",
    "bagg.fit(X_train, y_train)\n",
    "print('Done.')\n",
    "\n",
    "\n",
    "y_test_pred = bagg.predict_proba(testset[X_test.columns])\n",
    "test1 = testset.copy()\n",
    "test1['pred_prob'] = y_test_pred[:, 1]\n",
    "#print(test1.shape)\n",
    "\n",
    "output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], test1[\"pred_prob\"]), axis=1)\n",
    "#print(output.shape)\n",
    "\n",
    "output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\n",
    "output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)\n",
    "\n",
    "### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\n",
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "out.to_csv(\"bagging.csv\", header=[\"uid\", \"label\"], index=False) # submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Boosting Ensemble...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "'''We will use gradient boosting and extreme gradient boosting classifiers for boosting ensemble method.'''\n",
    "'''Initialize boosting classifier. Base models for boosting:'''\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "boost_models = [gbc, xgbc]\n",
    "boost = EnsembleVoteClassifier(clfs = boost_models, voting='hard')\n",
    "\n",
    "'''Fitting boosting.'''\n",
    "print('Fitting Boosting Ensemble...')\n",
    "boost.fit(X_train, y_train)\n",
    "print('Done.')\n",
    "\n",
    "y_test_pred = boost.predict_proba(testset[X_test.columns])\n",
    "test1 = testset.copy()\n",
    "test1['pred_prob'] = y_test_pred[:, 1]\n",
    "#print(test1.shape)\n",
    "\n",
    "output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], test1[\"pred_prob\"]), axis=1)\n",
    "#print(output.shape)\n",
    "\n",
    "output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\n",
    "output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)\n",
    "\n",
    "### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\n",
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "out.to_csv(\"boosting.csv\", header=[\"uid\", \"label\"], index=False) # submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
